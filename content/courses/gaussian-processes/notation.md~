---
date: "2020-03-31T00:00:00+01:00"
draft: false
linktitle: Definitions
menu:
  gaussian-processes:
    parent: Gaussian Processes
    weight: 2
title: Notation and Terminology
toc: true
type: docs
weight: 2
---

## Matrix/Vector Notation ##

In general, I will use an upper case letter for a matrix and a lower case letter for a vector. Vectors such as $v$ will almost always be accompanied by a description of an individual component $v_i$, referring to the $i$-th entry in the vector. If a vector's components are not specified I will bold it such as $\mathbf{v}$. I will write $X'$ to mean the transpose of a matrix $X$ or $v'$ to mean the transpose of a matrix $v$, as is common in regression analysis. 

## Matrix Calculus ##

For an $n\times 1$ vector $v$ and a scalar $f$ we will write $\dfrac{\partial v}{\partial f}$ to mean the $n\times 1$ vector with entries $\left(\dfrac{\partial v}{\partial f}\right)_i = \dfrac{\partial v_i}{\partial f}$. We will write $\dfrac{\partial f}{\partial v}$ to mean the $n\times 1$ vector with entries $\left(\dfrac{\partial f}{\partial v}\right)_i = \dfrac{\partial f}{\partial v_i}$. A useful resource for matrix calculus can be found on [Wikipedia](https://en.wikipedia.org/wiki/Matrix_calculus) or in the more extensive [Matrix Cookbook](https://www.math.uwaterloo.ca/~hwolkowi/matrixcookbook.pdf).

## Gaussian Process Notation ##

I will write $f \sim GP(\mu(x),k(x,x'))$ to denote a Gaussian process with mean function $\mu$ and covariance function (kernel) $k(x,x')$. I will in general _not_ assume that $k$ is stationary (see [terminology](#terminology)). Under this definition $f$ is a stochastic process with the defining property that for any set of points $\{x\_i\}$ (in whatever space $\Omega$ we choose), the vector $f(x)\_i = f(x\_i)$ is distributed as a multivariate normal (MVN) random vector with mean $\mu\_i = \mu(x\_i)$ and covariance matrix $\Sigma_{ij} = k(x_i,x_j)$. Many of the properties I will discuss on this page are actually properties of the MVN distribution.

## Terminology ##

- A Gaussian process is called _stationary_ (or _homogeneous_) if $k(x,x') = k(x-x')$
- A Gaussian Process is called _isotropic_ if $k(x,x') = k(|x-x'|)$
- A matrix $M$ is said to be _positive semidefinite_ if it has the property that $v'Mv \geq 0$ for any vector $v$. Covariance matrices are positive semidefinite.
- A kernel is said to be positive semidefinite (psd) if $$\int_\Omega k(x,x')f(x)f(x')dxdx' \geq 0$$ for all $L_2$ functions $f$. Gram matrices (i.e. covariance matrices) from psd kernels are psd matrices.
- The inverse of the covariance matrix in a MVN distribution is $Q = \Sigma^{-1}$ and is called the _precision matrix_. 
